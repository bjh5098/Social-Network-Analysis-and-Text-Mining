{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web scraping_1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjh5098/Social-Network-Analysis-and-Text-Mining/blob/master/Web_scraping_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8ZvUrpmUwSY",
        "colab_type": "text"
      },
      "source": [
        "***source :https://github.com/REMitchell/python-scraping***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWeC0Fp7Uv09",
        "colab_type": "text"
      },
      "source": [
        "# Web Scraping Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuVFJ3lqYtQ0",
        "colab_type": "text"
      },
      "source": [
        "## 웹 페이지 파싱 & 데이터 수집하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtWTZb1jPQAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z7ekOUrPaQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0anOr3t1PngF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(html.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTAhNm7jaPMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(html.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4FgtocUa0rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(html.getcode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wPYRmc9PzyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z90NfI5yd2Fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idvVX4xeSZMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html = urllib.request.urlopen(\"http://pythonscraping.com/pages/page1.html\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiHg2sQ9SlEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bsobj = BeautifulSoup(html.read(), 'html.parser')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Z0PbfUSsqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bsobj.h1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llB_sDFySy5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bsobj.div"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMaIHD-XMOx",
        "colab_type": "text"
      },
      "source": [
        "## 예외 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5DxIOrWbHV1",
        "colab_type": "text"
      },
      "source": [
        "***HTTP Error : https://ko.wikipedia.org/wiki/HTTP_%EC%83%81%ED%83%9C_%EC%BD%94%EB%93%9C***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAwntnegn4uL",
        "colab_type": "text"
      },
      "source": [
        "### URL, HTTP 에러"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgr_n1B0UjQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from urllib.error import URLError\n",
        "\n",
        "try:\n",
        "    # html = urlopen(\"http://pythonscraping.com/pages/page1.html\") # 정상 url 요청\n",
        "    html = urlopen(\"https://pythonscrapingthisurldoesnotexist.com\") # 오류 url 요청 에러 발생\n",
        "except URLError as e:\n",
        "    print(\"The server could not be found!\")\n",
        "except HTTPError as e:\n",
        "    print(\"The server returned an HTTP error\")\n",
        "else:\n",
        "    print(html.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OjbEUfsn8nr",
        "colab_type": "text"
      },
      "source": [
        "### 존재하지 않은 정보 요청 시 에러"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44smDz_vUkEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def getContent(url):\n",
        "    try:\n",
        "        html = urlopen(url)\n",
        "    except HTTPError as e:\n",
        "        return None\n",
        "    try:\n",
        "        bsObj = BeautifulSoup(html.read(), \"html.parser\")\n",
        "        # content = bsObj.body.h1 # 존재하는 정보(h1 tag) 요청\n",
        "        # content = bsObj.body.div # 존재하는 정보(div tag) 요청\n",
        "        content = bsObj.body.h2 # 존재하지 않은 정보(tag) 요청\n",
        "    except AttributeError as e:\n",
        "        return None\n",
        "    return content\n",
        "\n",
        "content = getContent(\"http://www.pythonscraping.com/pages/page1.html\")\n",
        "\n",
        "if content == None:\n",
        "    print(\"content could not be found\")\n",
        "else:\n",
        "    print(content)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}